<!-- (C) 2015 Rozum Halina, BSUIR -->
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//RU">
<HTML>

<HEAD>
    <LINK rel=stylesheet href="../../Оболочка/css/style.css" type=text/css>
    <META HTTP-EQUIV="Content-Type" CONTENT="text/html" charset="utf8">
    <META HTTP-EQUIV="Content-Language" CONTENT="ru">
    <title> Теория по дисциплине &quot;Операционные системы, базы данных&quot;</title>
    <base target="_top">
</HEAD>

<BODY>
    <table width="100%" border="0" cellpadding="0" cellspacing="3" background="../../Оболочка/images/background.jpg">
        <tr>
            <td width="13%" rowspan=3 align="center"><img src="../../Оболочка/images/logo_new.jpg" width=117 align="middle">
            </td>
            <tr>
                <td width="70%" colspan=2 align="center" valign="middle">
                    <H1 align="center">электронный
        ресурс по учебной дисциплине<BR>
        &quot;Операционные системы, базы данных&quot;<BR>
        для специальности: </H1> 1-58 01 01 - &quot;ИНЖЕНЕРНО-ПСИХОЛОГИЧЕСКОЕ ОБЕСПЕЧЕНИЕ ИНФОРМАЦИОННЫХ ТЕХНОЛОГИЙ&quot;.
                </td>
                <td width="12%" rowspan=3 align="center">&nbsp;</td>
  <Tr>
    <td align=center colspan=2><var class="normal">
                                                  <A HREF="../../index.htm">Оглавление</A> |
                                                  <A HREF="../../Программа/program.html" >Программа</A> | 
                                                    <strong>Теория</strong>|
                                                  <A HREF="../../Практика/practice.htm">Практика</A>|
                                                  <A HREF="../../Контроль_знаний/test.htm">Контроль знаний</A> |
                                                  <A HREF="../../Об авторах/author.htm">Об авторах</A>
     </var></var> </td>
  </tr>
    </table>

<table style="margin:0 auto;" width="90%" border="0" cellpadding="0" cellspacing="0">
            <td>
 <A HREF="../theory.htm">Оглавление</A>
                <p>&nbsp;</p>
                 <div> <p><a><b><span>Тема 3. Процессы и потоки<o:p></o:p></span></b></a></p> <span></span> <p><b><span><o:p> </o:p></span></b></p> <p><b><span>3.1 Понятия «процесс», «поток», «мультипрограммирование».<o:p></o:p></span></b></p> <p><b><span>Мультипрограммирование</span></b><i><span>, </span></i><span>или <span>многозадачность {</span></span><span>multitasking</span><span>),<i> </i></span><span>–<i> </i>это способ организации вычислительного процесса, при котором на одном процессоре попеременно выполняются сразу несколько программ. Эти программы совместно используют не только процессор, но и другие ресурсы компьютера: оперативную и внешнюю память, устройства ввода-вывода, данные. Мультипрограммирование призвано повысить эффективность использования вычислительной системы, однако эффективность может пониматься по-разному. Наиболее характерными критериями эффективности вычислительных систем являются:<o:p></o:p></span></p> <p> <span>пропускная способность </span><span>– количество задач, выполняемых вычислительной системой в единицу времени;<o:p></o:p></span></p> <p> <span>удобство работы пользователей;</span><span><o:p></o:p></span></p> <p> <span>реактивность системы<i> </i></span><span>–<i> </i>способность системы выдерживать заранее заданные (возможно, очень короткие) интервалы времени между запуском программы и получением результата.<o:p></o:p></span></p> <p><span>В зависимости от выбранного критерия эффективности ОС делятся на системы пакетной обработки, системы разделения времени и системы реального времени. Каждый тип ОС имеет специфические внутренние механизмы и особые области применения. Некоторые операционные системы могут поддерживать одновременно несколько режимов, например часть задач может выполняться в режиме пакетной обработки, а часть – в режиме реального времени или в режиме разделения времени.<o:p></o:p></span></p> <p><b><span>Мультипроцессорная обработка</span></b><i><span> </span></i><span>– это способ организации вычислительного про<span>цесса в системах с несколькими процессорами, при котором несколько задач </span>(процессов, потоков) могут одновременно выполняться на разных процессорах системы.<o:p></o:p></span></p> <p><span>Концепция мультипроцессирования ненова, она известна с 70-х годов, но до се<span>редины 80-х доступных многопроцессорных систем не существовало. Однако к </span><span>настоящему времени стало обычным включение нескольких процессоров в ар</span><span>хитектуру даже персонального компьютера. Более того, многопроцессорность </span>теперь является одним из необходимых требований, которые предъявляются к <span>компьютерам, используемым в качестве центрального сервера более-менее круп</span>ной сети.<o:p></o:p></span></p> <p><span>Не следует путать <i>мультипроцессорную </i>обработку с <i>мультипрограммной </i>обра</span><span>боткой. В мультипрограммных системах параллельная работа разных устройств позволяет одновременно вести обработку нескольких программ, но при этом в процессоре в каждый момент времени выполняется только <i>одна </i>программа. То есть в этом случае несколько задач выполняются попеременно на одном процессоре, создавая лишь видимость параллельного выполнения. А в мультипроцес<span>сорных системах <i>несколько задач </i>выполняются действительно <i>одновременно, </i>так </span><span>как имеется несколько обрабатывающих устройств </span>–<span> процессоров. Конечно, муль</span><span>типроцессирование вовсе не исключает мультипрограммирования: на каждом из </span>процессоров может попеременно выполняться некоторый закрепленный за данным процессором набор задач.<o:p></o:p></span></p> <p><span>Мультипроцессорная организация системы приводит к усложнению всех алго<span>ритмов управления ресурсами, например требуется планировать процессы не </span>для одного, а для нескольких процессоров, что гораздо сложнее. Сложности за<span>ключаются и в возрастании числа конфликтов по обращению к устройствам </span><span>ввода-вывода, данным, общей памяти и совместно используемым программам. Необходимо предусмотреть эффективные средства блокировки при доступе к </span>разделяемым информационным структурам ядра. Все эти проблемы должна ре<span>шать операционная система путем синхронизации процессов, ведения очередей </span>и планирования ресурсов. Более того, сама операционная система должна быть <span>спроектирована так, чтобы уменьшить существующие взаимозависимости между </span>собственными компонентами.<o:p></o:p></span></p> <p><span>В наши дни становится общепринятым введение в ОС функций поддержки мультипроцессорной обработки данных. Такие функции имеются во всех популярных ОС, таких как </span><span>SunSolaris</span><span> 2.</span><span>x</span><span>, </span><span>Santa Crus Operations Open Server</span><span> 3.</span><span>x</span><span>, </span><span>IBM </span><span>OS/2, </span><span>Microsoft Windows NT </span><span>и </span><span>Novell NetWare</span><span>, начиная с 4.1.</span><span><o:p></o:p></span></p> <p><span>Мультипроцессорные системы часто характеризуют либо как симметричные, либо как несимметричные. При этом следует четко определять, к какому аспекту мультипроцессорной системы относится эта характеристика – к типу архитектуры или к способу организации вычислительного процесса.<o:p></o:p></span></p> <p><b><span>Симметричная архитектура</span></b><i><span> </span></i><span>мультипроцессорной системы предполагает одно<span>родность всех процессоров и единообразие включения процессоров в общую </span>схему мультипроцессорной системы. Традиционные симметричные мультипро<span>цессорные конфигурации разделяют одну большую память между всеми процес</span>сорами.<o:p></o:p></span></p> <p><span>Масштабируемость, или возможность наращивания числа процессоров, в симмет</span><span>ричных системах ограничена вследствие того, что все они пользуются одной и <span>той же оперативной памятью и, следовательно, должны располагаться в одном корпусе. Такая конструкция, называемая <span>масштабируемой по вертикали<i>, </i></span>прак</span>тически ограничивает число процессоров до четырех или восьми.<o:p></o:p></span></p> <p><span>В симметричных архитектурах все процессы пользуются одной и той же схемой </span><span>отображения памяти. Они могут очень быстро обмениваться данными, так что обеспечивается достаточно высокая производительность для тех приложений <span>(например, при работе с базами данных), в которых несколько задач должны ак</span>тивно взаимодействовать между собой.<o:p></o:p></span></p> <p><span>В <span>асимметричной архитектуре<i> </i></span>разные процессоры могут отличаться как своими характеристиками (производительностью, надежностью, системой команд и т. д., вплоть до модели микропроцессора), так и функциональной ролью, которая по<span>ручается им в системе. Например, одни процессоры могут предназначаться для работы в качестве основных вычислителей, другие </span>–<span> для управления подсисте</span>мой ввода-вывода, третьи – еще для каких-то особых целей.<o:p></o:p></span></p> <p><span>Функциональная неоднородность в асимметричных архитектурах влечет за собой структурные отличия во фрагментах системы, содержащих разные процес<span>соры системы. Например, они могут отличаться схемами подключения про</span><span>цессоров к системной шине, набором периферийных устройств и способами </span>взаимодействия процессоров с устройствами.<o:p></o:p></span></p> <p><span>Масштабирование в асимметричной архитектуре реализуется иначе, чем в симметричной. Так как требование единого корпуса отсутствует, система может со<span>стоять из нескольких устройств, каждое из которых содержит один или несколь</span><span>ко процессоров. Это <span>масштабирование по горизонтали<i>. </i></span>Каждое такое устройство </span><span>называется <i>кластером, </i>а вся мультипроцессорная система </span>–<span> кластерной.</span><o:p></o:p></span></p> <p><span>Другим аспектом мультипроцессорных систем, который может характеризовать<span>ся симметрией или ее отсутствием, является способ организации вычислитель</span>ного процесса. Последний, как известно, определяется и реализуется операционной системой.<o:p></o:p></span></p> <p><i><span>Асимметричное мультипроцессирование </span></i><span>является наиболее простым способом </span><span>организации вычислительного процесса в системах с несколькими процессорами. Этот способ часто называют также «ведущий-ведомый».<o:p></o:p></span></p> <p><span>Функционирование системы по принципу «ведущий-ведомый» предполагает выделение одного из процессоров в качестве «ведущего», на котором работает операционная система и который управляет всеми остальными «ведомыми» процессорами. То есть ведущий процессор берет на себя функции распределения задач и ресурсов, а ведомые процессоры работают только как обрабатывающие устройства и никаких действий по организации работы вычислительной системы не выполняют.<o:p></o:p></span></p> <p><span>Так как операционная система работает только на одном процессоре и функции </span><span>управления полностью централизованы, то такая операционная система оказывается не намного сложнее ОС однопроцессорной системы.<o:p></o:p></span></p> <p><span>Асимметричная организация вычислительного процесса может быть реализована как для симметричной мультипроцессорной архитектуры, в которой все процессоры аппаратно неразличимы, так и для несимметричной, для которой характерна неоднородность процессоров, их специализация на аппаратном уровне.<o:p></o:p></span></p> <p><span>В архитектурно-асимметричных системах на роль ведущего процессора может быть назначен наиболее надежный и производительный процессор. Если в наборе процессоров имеется специализированный процессор, ориентированный, на<span>пример, на матричные вычисления, то при планировании процессов операци</span>онная система, реализующая асимметричное мультипроцессирование, должна учитывать специфику этого процессора. Такая специализация снижает надеж<span>ность системы в целом, так как процессоры не являются взаимозаменяемыми.</span><o:p></o:p></span></p> <p><i><span>Симметричное мультипроцессирование </span></i><span>как способ организации вычислительного процесса может быть реализовано в системах только с симметричной мульти<span>процессорной архитектурой. Напомним, что в таких системах процессоры работают с общими устройствами и разделяемой основной памятью. </span><span>Симметричное мультипроцессирование реализуется общей для всех процес</span><span>соров операционной системой. При симметричной организации все процессоры равноправно участвуют и в управлении вычислительным процессом, и в выпол</span>нении прикладных задач. Например, сигнал прерывания от принтера, который <span>распечатывает данные прикладного процесса, выполняемого на некотором про</span>цессоре, может быть обработан совсем другим процессором. Разные процессоры <span>могут в какой-то момент одновременно обслуживать как разные, так и одинаковые модули общей операционной системы. Для этого программы операционной системы должны обладать свойством повторной входимости <i>(реентерабельнос</i></span><i>тью).</i><o:p></o:p></span></p> <p><span>Операционная система полностью децентрализована. Модули ОС выполняются на любом доступном процессоре. Как только процессор завершает выполнение очередной задачи, он передает управление планировщику задач, который выбирает из общей для всех процессоров системной очереди задачу, которая будет выполняться на данном процессоре следующей. Все ресурсы выделяются для каж<span>дой выполняемой задачи по мере возникновения в них потребностей и никак не закрепляются за процессором. При таком подходе все процессоры работают </span><span>с одной и той же динамически выравниваемой нагрузкой. В решении одной за</span>дачи могут участвовать сразу несколько процессоров, если она допускает такое распараллеливание, например путем представления в виде нескольких потоков.<o:p></o:p></span></p> <p><span>В случае отказа одного из процессоров симметричные системы, как правило, сравнительно просто реконфигурируются, что является их большим преимуществом перед плохо реконфигурируемыми асимметричными системами.<o:p></o:p></span></p> <p><span>Симметричная и асимметричная организация вычислительного процесса в муль</span><span>типроцессорной системе не связана напрямую с симметричной или асимметричной архитектурой, она определяется типом операционной системы. Так, в симметричных архитектурах вычислительный процесс может быть организован как симметричным образом, так и асимметричным. Однако асимметричная архитектура непременно влечет за собой и асимметричный способ организации вычислений.<o:p></o:p></span></p> <p><span>Чтобы поддерживать мультипрограммирование, ОС должна определить и оформить для себя те внутренние единицы работы, между которыми будет разделяться процессор и другие ресурсы компьютера. В настоящее время в большинстве операционных систем определены два типа единиц работы. Более крупная единица работы, обычно носящая название <b><i>процесса</i></b><i>, </i>или<i>задачи, </i>требует для своего выполнения нескольких более мелких работ, для обозначения которых используют термины <i>«<b>поток</b>*, </i>или <i>«нить*.</i><o:p></o:p></span></p> <p><span>Любая работа вычислительной системы заключается в выполнении некоторой программы. Поэтому и с процессом, и с потоком связывается определенный программный код, который для этих целей оформляется в виде исполняемого модуля. Чтобы этот программный код мог быть выполнен, его необходимо загрузить в оперативную память, возможно, выделить некоторое место на диске для хранения данных, предоставить доступ к устройствам ввода-вывода, например к последовательному порту для получения данных по подключенному к этому порту модему, и т. д. В ходе выполнения программе может также понадобиться доступ к информационным ресурсам, например файлам, портам </span><span>TCP</span><span>/</span><span>UPD</span><span>, семафорам. И, конечно же, невозможно выполнение программы без предоставления ей процессорного времени, то есть времени, в течение которого процессор выполняет коды данной программы.<o:p></o:p></span></p> <p><span>В операционных системах, где существуют и процессы, и потоки, процесс рассматривается операционной системой как заявка на потребление всех видов ре<span>сурсов, кроме одного </span>–<span> процессорного времени. Этот последний важнейший </span>ресурс распределяется операционной системой между другими единицами работы – потоками, которые и получили свое название благодаря тому, что они <span>представляют собой последовательности (потоки выполнения) команд.</span><o:p></o:p></span></p> <p><span>В простейшем случае процесс состоит из одного потока, и именно таким образом трактовалось понятие «процесс» до середины 80-х годов (например, в ранних версиях </span><span>UNIX</span><span>) и в таком же виде оно сохранилось в некоторых современ<span>ных ОС. В таких системах понятие «поток» полностью поглощается понятием </span><span>«процесс», то есть остается только одна единица работы и потребления ресур</span><span>сов </span>–<span> процесс. Мультипрограммирование осуществляется в таких ОС на уровне </span>процессов.<o:p></o:p></span></p> <p><span>Для того чтобы процессы не могли вмешаться в распределение ресурсов, а также не могли повредить коды и данные друг друга, важнейшей задачей ОС является <i>изоляция </i>одного процесса от другого. Для этого операционная система обеспечивает каждый процесс отдельным виртуальным адресным пространством, так что ни один процесс не может получить прямого доступа к командам и данным другого процесса.<o:p></o:p></span></p> <p><span>Однако в системах, в которых отсутствует понятие потока, возникают проблемы </span><span>при организации параллельных вычислений в рамках процесса. А такая необходимость может возникать. Действительно, при мультипрограммировании по<span>вышается пропускная способность системы, но отдельный процесс никогда не может быть выполнен быстрее, чем в однопрограммном режиме (всякое разделе</span>ние ресурсов только замедляет работу одного из участников за счет дополнительных затрат времени на ожидание освобождения ресурса). Однако приложе<span>ние, выполняемое в рамках одного процесса, может обладать внутренним парал</span>лелизмом, который в принципе мог бы позволить ускорить его решение. Если, <span>например, в программе предусмотрено обращение к внешнему устройству, то на </span>время этой операции можно не блокировать выполнение всего процесса, а про<span>должить вычисления по другой ветви программы. Параллельное выполнение </span>нескольких работ в рамках одного интерактивного приложения повышает эф<span>фективность работы пользователя. Так, при работе с текстовым редактором </span><span>желательно иметь возможность совмещать набор нового текста с такими продол</span><span>жительными по времени операциями, как переформатирование значительной час</span>ти текста, печать документа или его сохранение на локальном или удаленном диске. Еще одним примером необходимости распараллеливания является сетевой сервер баз данных. В этом случае параллелизм желателен как для обслуживания различных запросов к базе данных, так и для более быстрого выполнения <span>отдельного запроса за счет одновременного просмотра различных записей базы.</span><o:p></o:p></span></p> <p><span>Потоки возникли в операционных системах как средство распараллеливания вычислений. Конечно, задача распараллеливания вычислений в рамках одного при<span>ложения может быть решена и традиционными способами.</span><o:p></o:p></span></p> <p><span>Во-первых, прикладной программист может взять на себя сложную задачу организации параллелизма, выделив в приложении некоторую подпрограмму-диспет<span>чер, которая периодически передает управление той или иной ветви вычислений. </span><span>При этом программа получается логически весьма запутанной, с многочислен</span>ными передачами управления, что существенно затрудняет ее отладку и модификацию.<o:p></o:p></span></p> <p><span>Во-вторых, решением является создание для одного приложения нескольких процессов для каждой из параллельных работ. Однако использование для создания процессов стандартных средств ОС не позволяет учесть тот факт, что эти процессы решают единую задачу, а значит, имеют много общего между собой – они <span>могут работать с одними и теми же данными, использовать один и тот же кодовый сегмент, наделяться одними и теми же правами доступа к ресурсам вычис</span>лительной системы. Так, если в примере с сервером баз данных создавать от<span>дельные процессы для каждого запроса, поступающего из сети, то все процессы </span>будут выполнять один и тот же программный код и выполнять поиск в записях, <span>общих для всех процессов файлов данных. А операционная система при таком подходе будет рассматривать эти процессы наравне со всеми остальными про</span>цессами и с помощью универсальных механизмов обеспечивать их изоляцию друг <span>от друга. В данном случае все эти достаточно громоздкие механизмы использу</span><span>ются явно не по назначению, выполняя не только бесполезную, но и вредную </span>работу, затрудняющую обмен данными между различными частями приложения. <span>Кроме того, на создание каждого процесса ОС тратит определенные системные ресурсы, которые в данном случае неоправданно дублируются </span>–<span> каждому процессу выделяются собственное виртуальное адресное пространство, физическая </span>память, закрепляются устройства ввода-вывода и т. п.<o:p></o:p></span></p> <p><span>Из всего вышеизложенного следует, что в операционной системе наряду с процессами нужен другой механизм распараллеливания вычислений, который учи<span>тывал бы тесные связи между отдельными ветвями вычислений одного и того же </span>приложения. Для этих целей современные ОС предлагают механизм <i>многопо<span>точной обработки (</span></i></span><i><span>multithreading</span></i><i><span>). </span></i><span>При этом вводится новая единица работы </span><span>–<span> </span>поток выполнения, а понятие «процесс» в значительной степени меняет смысл. <span>Понятию «поток» соответствует последовательный переход процессора от одной </span><span>команды программы к другой. ОС распределяет процессорное время между пото</span>ками. Процессу ОС назначает адресное пространство и набор ресурсов, которые совместно используются всеми его потоками.<o:p></o:p></span></p> <p><span>Создание потоков требует от ОС меньших накладных расходов, чем процессов. </span><span>В отличие от процессов, которые принадлежат разным, вообще говоря, конкурирующим приложениям, все потоки одного процесса всегда принадлежат одному приложению, поэтому ОС изолирует потоки в гораздо меньшей степени, нежели процессы в традиционной мультипрограммной системе. Все потоки одного процесса используют общие файлы, таймеры, устройства, одну и ту же область оперативной памяти, одно и то же адресное пространство. Это означает, что они разделяют одни и те же глобальные переменные. Поскольку каждый поток может иметь доступ к любому виртуальному адресу процесса, один поток может использовать стек другого потока. Между потоками одного процесса нет полной защиты, потому что, во-первых, это невозможно, а во-вторых, не нужно. Чтобы организовать взаимодействие и обмен данными, потокам вовсе не требуется обращаться к ОС, им достаточно использовать общую память – один поток записывает данные, а другой читает их. С другой стороны, потоки разных процессов по-прежнему хорошо защищены друг от друга.<o:p></o:p></span></p> <p><span>Итак, мультипрограммирование более эффективно на уровне потоков, а не процес</span><span>сов. Каждый поток имеет собственный счетчик команд и стек. Задача, оформленная в виде нескольких потоков в рамках одного процесса, может быть выполнена <span>быстрее за счет псевдопараллельного (или параллельного в мультипроцессорной системе) выполнения ее отдельных частей. Например, если электронная таблица была разработана с учетом возможностей многопоточной обработки, то пользо</span>ватель может запросить пересчет своего рабочего листа и одновременно продол<span>жать заполнять таблицу. Особенно эффективно можно использовать многопо</span><span>точность для выполнения распределенных приложений, например многопоточный </span><span>сервер может параллельно выполнять запросы сразу нескольких клиентов.</span><o:p></o:p></span></p> <p><span>Использование потоков связано не только со стремлением повысить производи<span>тельность системы за счет параллельных вычислений, но и с целью создания </span><span>более читабельных, логичных программ. Введение нескольких потоков выполнения упрощает программирование. Например, в задачах типа «писатель-читатель» </span>один поток выполняет запись в буфер, а другой считывает записи из него. Поскольку они разделяют общий буфер, не стоит их делать отдельными процесса<span>ми. Другой пример использования потоков </span>–<span> управление сигналами, такими как прерывание с клавиатуры (</span></span><span>del</span><span>или </span><span>break</span><span>). Вместо обработки сигнала прерывания </span><span>один поток назначается для постоянного ожидания поступления сигналов. Та</span><span>ким образом, использование потоков может сократить необходимость в прерыва</span><span>ниях пользовательского уровня. В этих примерах не столь важно параллельное </span><span>выполнение, сколь важна ясность программы.<o:p></o:p></span></p> <p><span>Наибольший эффект от введения многопоточной обработки достигается в мультипроцессорных системах, в которых потоки, в том числе и принадлежащие одному процессу, могут выполняться на разных процессорах действительно параллельно (а не псевдопараллельно).<o:p></o:p></span></p> <p><span><o:p> </o:p></span></p> <p><b><span>3.2 Создание процессов и потоков<o:p></o:p></span></b></p> <p><span>Каждый процесс имеет хотя бы один выполняющийся поток. Тот поток, с которого начинается выполнение программы, называется главным. В языке Java, после создания процесса, выполнение главного потока начинается с метода main(). Затем, по мере необходимости, в заданных программистом местах, и при выполнении заданных им же условий, запускаются другие, побочные потоки.</span><span><br> <span>В языке Java поток представляется в виде объекта-потомка класса Thread. Этот класс инкапсулирует стандартные механизмы работы с потоком.</span><br> <span>Запустить новый поток можно двумя способами:</span><br> Способ 1. <span>Создать объект класса Thread, передав ему в конструкторе нечто, реализующее интерфейс Runnable. Этот интерфейс содержит метод run(), который будет выполняться в новом потоке. Поток закончит выполнение, когда завершится его метод run().</span><o:p></o:p></span></p> <p><span><o:p> </o:p></span></p> <p><span>class SomeThing<span> </span>implements Runnable{<o:p></o:p></span></p> <p><span><span> </span>public void run() {<span> </span>//Этот метод будет выполняться в побочном потоке<o:p></o:p></span></p> <p><span><span> </span></span><span>System.out.println("It’s the second thread!");<o:p></o:p></span></p> <p><span><span> </span><span> </span>}<o:p></o:p></span></p> <p><span>}<o:p></o:p></span></p> <p><span><o:p> </o:p></span></p> <p><span>public class Program {<o:p></o:p></span></p> <p><span><span> </span>static SomeThing mThing;<span> </span>//mThing </span><span>объект</span><span> </span><span>класса</span><span>, </span><span>реализующего</span><span> </span><span>интерфейс</span><span> Runnable<o:p></o:p></span></p> <p><span><span> </span>public static void main(String[] args) {<o:p></o:p></span></p> <p><span><span> </span>mThing = new SomeThing();<o:p></o:p></span></p> <p><span><span> </span>Thread myThread = new Thread(mThing);<span> </span>//</span><span>Создание</span><span> </span><span>потока</span><span> "myThread"<o:p></o:p></span></p> <p><span><span> </span>myThread.start();<span> </span>//</span><span>Запуск</span><span> </span><span>потока</span><span><o:p></o:p></span></p> <p><span><span> </span>System.out.println("Main thread is finished.");<o:p></o:p></span></p> <p><span><span> </span></span><span>}<o:p></o:p></span></p> <p><span>}<o:p></o:p></span></p> <p><span><o:p> </o:p></span></p> <p><span>Способ 2. <span>Создать потомка класса Thread и переопределить его метод run():</span><o:p></o:p></span></p> <p><span><o:p> </o:p></span></p> <p><span>class AffableThread extends Thread {<o:p></o:p></span></p> <p><span><span> </span>@Override<o:p></o:p></span></p> <p><span><span> </span>public void run()<span> </span>//Этот метод будет выполнен в побочном потоке<o:p></o:p></span></p> <p><span><span> </span></span><span>{<o:p></o:p></span></p> <p><span><span> </span>System.out.println("It’s the second thread!");<o:p></o:p></span></p> <p><span><span> </span>}<o:p></o:p></span></p> <p><span>}<o:p></o:p></span></p> <p><span><o:p> </o:p></span></p> <p><span>public class Program {<o:p></o:p></span></p> <p><span><span> </span>static AffableThread mSecondThread;<o:p></o:p></span></p> <p><span><span> </span><o:p></o:p></span></p> <p><span><span> </span>public static void main(String[] args)<o:p></o:p></span></p> <p><span><span> </span>{<o:p></o:p></span></p> <p><span><span> </span><span> </span>mSecondThread = new AffableThread();<span> </span>//</span><span>Создание</span><span> </span><span>потока</span><span><o:p></o:p></span></p> <p><span><span> </span>mSecondThread.start();<span> </span>//</span><span>Запуск</span><span> </span><span>потока</span><span><o:p></o:p></span></p> <p><span><span> </span><o:p></o:p></span></p> <p><span><span> </span>System.out.println("Main thread is finished.");<o:p></o:p></span></p> <p><span><span> </span></span><span>}<o:p></o:p></span></p> <p><span>}<o:p></o:p></span></p> <p><span><o:p> </o:p></span></p> <p><span>В приведённом выше примере в методе main() создается и запускается еще один поток. Важно отметить, что после вызова метода mSecondThread.start() главный поток продолжает своё выполнение, не дожидаясь пока порожденный им поток завершится. И те инструкции, которые идут после вызова метода start(), будут выполнены параллельно с инструкциями потока mSecondThread.<o:p></o:p></span></p> <p><span><o:p> </o:p></span></p> <p><b><span>3.3 </span></b><b><span>Планирование и диспетчеризация потоков<o:p></o:p></span></b></p> <p><span>На протяжении существования процесса выполнение его потоков может быть многократно прервано и продолжено. (В системе, не поддерживающей потоки, все сказанное ниже о планировании и диспетчеризации относится к процессу в целом.)<o:p></o:p></span></p> <p><span>Переход от выполнения одного потока к другому осуществляется в результате планирования и диспетчеризации. Работа по определению того, в какой момент необходимо прервать выполнение текущего активного потока и какому потоку предоставить возможность выполняться, называется <i>планированием. </i>Планирование потоков осуществляется на основе информации, хранящейся в описателях процессов и потоков. При планировании могут приниматься во внимание приоритет потоков, время их ожидания в очереди, накопленное время выполнения, <span>интенсивность обращений к вводу-выводу и другие факторы. ОС планирует вы</span>полнение потоков независимо от того, принадлежат ли они одному или разным процессам. Так, например, после выполнения потока некоторого процесса ОС <span>может выбрать для выполнения другой поток того же процесса или же назна</span>чить к выполнению поток другого процесса.<o:p></o:p></span></p> <p><span>Планирование потоков, по существу, включает в себя решение двух задач:<o:p></o:p></span></p> <p> <span>определение момента времени для смены текущего активного потока;<o:p></o:p></span></p> <p> <span>выбор для выполнения потока из очереди готовых потоков.</span><span><o:p></o:p></span></p> <p><span>Существует множество различных алгоритмов планирования потоков, по-своему </span><span>решающих каждую из приведенных выше задач. Алгоритмы планирования могут преследовать различные цели и обеспечивать разное качество мультипро<span>граммирования. Например, в одном случае выбирается такой алгоритм планиро</span>вания, при котором гарантируется, что ни один поток/процесс не будет занимать процессор дольше определенного времени, в другом случае целью является максимально быстрое выполнение «коротких» задач, а в третьем случае – преимущественное право занять процессор получают потоки интерактивных приложе<span>ний. Именно особенности реализации планирования потоков в наибольшей степени </span><span>определяют специфику операционной системы, в частности, является ли она сис</span>темой пакетной обработки, системой разделения времени или системой реального времени.<o:p></o:p></span></p> <p><span>В большинстве операционных систем универсального назначения планирование осуществляется <i>динамически </i>(</span><span>on</span><span>-</span><span>line</span><span>), то есть решения принимаются во время работы системы на основе анализа текущей ситуации. ОС работает в условиях неопределенности – потоки и процессы появляются в случайные моменты вре<span>мени и также непредсказуемо завершаются. Динамические планировщики могут </span>гибко приспосабливаться к изменяющейся ситуации и не используют никаких <span>предположений о мультипрограммной смеси. Для того чтобы оперативно найти в условиях такой неопределенности оптимальный в некотором смысле порядок выполнения задач, операционная система должна затрачивать значительные усилия.</span><o:p></o:p></span></p> <p><span>Другой тип планирования – статический – может быть использован в специа<span>лизированных системах, в которых весь набор одновременно выполняемых за</span>дач определен заранее, например в системах реального времени. <i>Планировщик</i><span> </span><span>называется <i>статическим </i>(или предварительным планировщиком), если он принимает решения о планировании не во время работы системы, а заранее (</span></span><span>off</span><span>-</span><span>line</span><span>). </span><span>Соотношение между динамическим и статическим планировщиками аналогично соотношению между диспетчером железной дороги, который пропускает поезда строго по предварительно составленному расписанию, и регулировщиком на перекрестке автомобильных дорог, не оснащенном светофорами, который решает, какую машину остановить, а какую пропустить, в зависимости от ситуации на перекрестке.<o:p></o:p></span></p> <p><span>Результатом работы статического планировщика является таблица, называемая расписанием, в которой указывается, какому потоку/процессу, когда и на какое время должен быть предоставлен процессор. Для построения расписания планировщику нужны как можно более полные предварительные знания о характеристиках набора задач, например о максимальном времени выполнения каждой задачи, ограничениях предшествования, ограничениях по взаимному исключению, предельным срокам и т. д.<o:p></o:p></span></p> <p><span>После того как расписание готово, оно может использоваться операционной сис</span><span>темой для переключения потоков и процессов. При этом накладные расходы ОС на исполнение расписания оказываются значительно меньшими, чем при дина<span>мическом планировании, и сводятся лишь к диспетчеризации потоков/процессов.</span><o:p></o:p></span></p> <p><span>С самых общих позиций все множество алгоритмов планирования можно разде<span>лить на два класса: вытесняющие и невытесняющие алгоритмы планирования.</span><o:p></o:p></span></p> <p><i><span>Невытесняющие (поп-</span></i><i><span>preemptive</span></i><i><span>) </span></i><span>алгоритмы основаны на том, что активному <span>потоку позволяется выполняться, пока он сам, по собственной инициативе, </span>не отдаст управление операционной системе для того, чтобы та выбрала из очереди другой готовый к выполнению поток.<o:p></o:p></span></p> <p><i><span>Вытесняющие (</span></i><i><span>preemptive</span></i><i><span>) </span></i><span>алгоритмы – это такие способы планирования потоков, в которых решение о переключении процессора с выполнения одного потока на выполнение другого потока принимается операционной системой, а не активной задачей.<o:p></o:p></span></p> <p><span>Основным различием между вытесняющими и невытесняющими алгоритмами <span>является степень централизации механизма планирования потоков. При вытес</span>няющем мультипрограммировании функции планирования потоков целиком со<span>средоточены в операционной системе и программист пишет свое приложение, не </span><span>заботясь о том, что оно будет выполняться одновременно с другими задачами. </span>При этом операционная система выполняет следующие функции: определяет момент снятия с выполнения активного потока, запоминает его контекст, выбирает из очереди готовых потоков следующий, запускает новый поток на выполнение, загружая его контекст.<o:p></o:p></span></p> <p><span>При невытесняющем мультипрограммировании механизм планирования распре<span>делен между операционной системой и прикладными программами. Прикладная </span>программа, получив управление от операционной системы, сама определяет мо<span>мент завершения очередного цикла своего выполнения и только затем переда</span><span>ет управление ОС с помощью какого-либо системного вызова. ОС формирует </span>очереди потоков и выбирает в соответствии с некоторым правилом (например, с учетом приоритетов) следующий поток на выполнение. Такой механизм создает проблемы как для пользователей, так и для разработчиков приложений.<o:p></o:p></span></p> <p><span>Для пользователей это означает, что управление системой теряется на произ</span><span>вольный период времени, который определяется приложением (а не пользова<span>телем). Если приложение тратит слишком много времени на выполнение какой-</span>либо работы, например на форматирование диска, пользователь не может пере<span>ключиться с этой задачи на другую задачу, например на текстовый редактор, в то </span><span>время как форматирование продолжалось бы в фоновом режиме.</span><o:p></o:p></span></p> <p><span>Поэтому разработчики приложений для операционной среды с невытесняющей многозадачностью вынуждены, возлагая на себя часть функций планировщика, создавать приложения так, чтобы они выполняли свои задачи небольшими час<span>тями. Например, программа форматирования может отформатировать одну до</span>рожку дискеты и вернуть управление системе. После выполнения других задач <span>система возвратит управление программе форматирования, чтобы та отформати</span><span>ровала следующую дорожку. Подобный метод разделения времени между задача</span>ми работает, но он существенно затрудняет разработку программ и предъявляет повышенные требования к квалификации программиста. Программист должен <span>обеспечить «дружественное» отношение своей программы к другим выполняемым одновременно с ней программам. Для этого в программе должны быть пре</span>дусмотрены частые передачи управления операционной системе. Крайним про<span>явлением «не дружественности» приложения является его зависание, которое </span>приводит к общему краху системы. В системах с вытесняющей многозадачностью такие ситуации, как правило, исключены, так как центральный планирую<span>щий механизм имеет возможность снять зависшую задачу с выполнения.</span><o:p></o:p></span></p> <p><span>Однако распределение функций планирования потоков между системой и приложениями не всегда является недостатком, а при определенных условиях может быть и преимуществом, потому что дает возможность разработчику прило<span>жений самому проектировать алгоритм планирования, наиболее подходящий для </span>данного фиксированного набора задач. Так как разработчик сам определяет в <span>программе момент возвращения управления, то при этом исключаются нерацио</span><span>нальные прерывания программ в «неудобные» для них моменты времени. Кроме </span>того, легко разрешаются проблемы совместного использования данных: задача во время каждого цикла выполнения использует их монопольно и уверена, что на протяжении этого периода никто другой не изменит данные. Существенным <span>преимуществом не вытесняющего планирования является более высокая скорость </span>переключения с потока на поток.<o:p></o:p></span></p> <p><span>Почти во всех современных операционных системах, ориентированных на высокопроизводительное выполнение приложений (</span><span>UNIX</span><span>, </span><span>Windows NT</span><span>/2000, OS/2, </span><span>VAX</span><span>/</span><span>VMS</span><span>), реализованы вытесняющие алгоритмы планирования потоков (про</span><span>цессов). В последнее время дошла очередь и до ОС класса настольных систем, например OS/2 </span><span>Warp </span><span>и </span><span>Windows </span><span>95/98.<o:p></o:p></span></p> <p><span><o:p> </o:p></span></p> <p><span><o:p> </o:p></span></p> <p><b><span>3.4 </span></b><b><span>Алгоритмы планирования, основанные на квантовании</span></b><b><span><o:p></o:p></span></b></p> <p><span>В основе многих вытесняющих алгоритмов планирования лежит концепция <i><span>квантования. </span></i><span>В соответствии с этой концепцией каждому потоку поочередно для </span>выполнения предоставляется ограниченный непрерывный период процессорного времени – <i>квант. </i>Смена активного потока происходит, если:<o:p></o:p></span></p> <p> <span>поток завершился и покинул систему;<o:p></o:p></span></p> <p> <span>произошла ошибка;<o:p></o:p></span></p> <p> <span>поток перешел в состояние ожидания;<o:p></o:p></span></p> <p> <span>исчерпан квант процессорного времени, отведенный данному потоку.<o:p></o:p></span></p> <p><span>Поток, который исчерпал свой квант, переводится в состояние готовности и ожидает, когда ему будет предоставлен новый квант процессорного времени, а на выполнение в соответствии с определенным правилом выбирается новый поток из очереди готовых. Граф состояний потока, изображенный на рисунке 1 соответствует алгоритму планирования, основанному на квантовании.<o:p></o:p></span></p> <p><span> </span><a></a><span><!--[if gte vml 1]><v:shapetype
 id="_x0000_t75" coordsize="21600,21600" o:spt="75" o:preferrelative="t"
 path="m@4@5l@4@11@9@11@9@5xe" filled="f" stroked="f">
 <v:stroke joinstyle="miter"/>
 <v:formulas>
  <v:f eqn="if lineDrawn pixelLineWidth 0"/>
  <v:f eqn="sum @0 1 0"/>
  <v:f eqn="sum 0 0 @1"/>
  <v:f eqn="prod @2 1 2"/>
  <v:f eqn="prod @3 21600 pixelWidth"/>
  <v:f eqn="prod @3 21600 pixelHeight"/>
  <v:f eqn="sum @0 0 1"/>
  <v:f eqn="prod @6 1 2"/>
  <v:f eqn="prod @7 21600 pixelWidth"/>
  <v:f eqn="sum @8 21600 0"/>
  <v:f eqn="prod @7 21600 pixelHeight"/>
  <v:f eqn="sum @10 21600 0"/>
 </v:formulas>
 <v:path o:extrusionok="f" gradientshapeok="t" o:connecttype="rect"/>
 <o:lock v:ext="edit" aspectratio="t"/>
</v:shapetype><v:shape id="_x0000_i1025" type="#_x0000_t75" style='width:415.5pt;
 height:298.5pt'>
 <v:imagedata src="Тема%20№3.files/image001.png" o:title=""/>
</v:shape><![endif]--><img src="Тема%20№3.files/image002.jpg" v:shapes="_x0000_i1025"><o:p></o:p></span></p> <p style="text-align: center;"><span>Рисунок <a></a>1 – Граф состояний потока в системе с квантованием<o:p></o:p></span></p> <p style="text-align: center;"><span><o:p> </o:p></span></p> <p><span>Кванты, выделяемые потокам, могут быть одинаковыми для всех потоков или <span>различными. Рассмотрим, например, случай, когда всем потокам предоставляют</span>ся кванты одинаковой длины <b>q </b>(рисунок 2). Если в системе имеется <b>n</b> потоков, то <span>время, которое поток проводит в ожидании следующего кванта, можно грубо оце</span><span>нить как </span><b>q(n-l)</b><span>. Чем больше потоков в системе, тем больше время ожидания, тем меньше возможности вести одновременную интерактивную работу нескольким пользователям. Но если величина кванта выбрана очень небольшой, то значение </span>произведения <b>q(n-l) </b>все равно будет достаточно мало для того, чтобы пользователь не ощущал дискомфорта от присутствия в системе других пользователей. <span>Типичное значение кванта в системах разделения времени составляет десятки </span>миллисекунд.<o:p></o:p></span></p> <p><span><o:p> </o:p></span></p> <p style="text-align: center;"><span><o:p> </o:p></span></p> <p><span> <o:p></o:p></span></p> <p><span><o:p> </o:p></span></p> <p style="text-align: center;"><span><!--[if gte vml 1]><v:shape
 id="_x0000_i1026" type="#_x0000_t75" style='width:387pt;height:247.5pt'>
 <v:imagedata src="Тема%20№3.files/image003.png" o:title=""/>
</v:shape><![endif]--><img src="Тема%20№3.files/image004.jpg" v:shapes="_x0000_i1026"><o:p></o:p></span></p>
 <p style="text-align: center;"><span>Рисунок 2 – Иллюстрация расчета времени ожидания в очереди<o:p></o:p></span></p> <p><span> <o:p></o:p></span></p> <p><span>Если квант короткий, то суммарное время, которое проводит поток в ожидании процессора, прямо пропорционально времени, требуемому для его выполне<span>ния (то есть времени, которое потребовалось бы для выполнения этого потока при монопольном использовании вычислительной системы). Действительно, </span>поскольку время ожидания между двумя циклами выполнения равно <b>q(n-l)</b>, <span>а количество циклов </span><b>B/q</b><span>, где </span><b>В</b><span> </span>–<span> требуемое время выполнения, то </span><b>W-B(n-l)</b><span>. За</span><span>метим, что эти соотношения представляют собой весьма грубые оценки, осно</span><span>ванные на предположении, что </span><b>В </b><span>значительно превышает </span><b>q</b><span>. При этом не учиты</span>вается, что потоки могут использовать кванты не полностью, что часть времени <span>они могут тратить на ввод-вывод, что количество потоков в системе может ди</span>намически меняться и т.д.<o:p></o:p></span></p> <p><span>Чем больше квант, тем выше вероятность того, что потоки завершатся в ре<span>зультате первого же цикла выполнения, и тем менее явной становится зависи</span>мость времени ожидания потоков от их времени выполнения. При достаточно большом кванте алгоритм квантования вырождается в алгоритм последова<span>тельной обработки, присущий однопрограммным системам, при котором вре</span>мя ожидания задачи в очереди вообще никак не зависит от ее длительности.<o:p></o:p></span></p> <p><span>Кванты, выделяемые одному потоку, могут быть фиксированной величины, а могут и изменяться в разные периоды жизни потока. Пусть, например, перво<span>начально каждому потоку назначается достаточно большой квант, а величина </span>каждого следующего кванта уменьшается до некоторой заранее заданной величины. В таком случае преимущество получают короткие задачи, которые успевают выполняться в течение первого кванта, а длительные вычисления будут проводиться в фоновом режиме. Можно представить себе алгоритм планирования, в котором каждый следующий квант, выделяемый определенному потоку, больше предыдущего. Такой подход позволяет уменьшить на<span>кладные расходы на переключение задач в том случае, когда сразу несколько</span>задач выполняют длительные вычисления.<o:p></o:p></span></p> <p><span>Потоки получают для выполнения квант времени, но некоторые из них ис</span><span>пользуют его не полностью, например из-за необходимости выполнить ввод или вывод данных. В результате возникает ситуация, когда потоки с интен<span>сивными обращениями к вводу-выводу используют только небольшую часть выделенного им процессорного времени. Алгоритм планирования может исправить эту «несправедливость». В качестве компенсации за неиспользованные полностью кванты потоки получают привилегии при последующем об</span>служивании. Для этого планировщик создает две очереди готовых потоков (рисунок 3). Очередь 1 образована потоками, которые пришли в состояние го<span>товности в результате исчерпания кванта времени, а очередь 2 </span>–<span> потоками, у</span><span>которых завершилась операция ввода-вывода. При выборе потока для выпол</span><span>нения прежде всего просматривается вторая очередь, и только если она пуста, </span>квант выделяется потоку из первой очереди,<o:p></o:p></span></p> <p><span>Многозадачные ОС теряют некоторое количество процессорного времени для выполнения вспомогательных работ во время переключения контекстов задач. При этом запоминаются и восстанавливаются регистры, флаги и указатели стека, а также проверяется статус задач для передачи управления. Затраты на эти <span>вспомогательные действия не зависят от величины кванта времени, поэтому чем больше квант, тем меньше суммарные накладные расходы, связанные с переклю</span>чением потоков.<o:p></o:p></span></p> <p><span>В алгоритмах, основанных на квантовании, какую бы цель они не преследовали (предпочтение коротких или длинных задач, компенсация недоиспользованного кванта или минимизация накладных расходов, связанных с переключениями), не используется никакой предварительной информации о задачах. При поступлении задачи на обработку ОС не имеет никаких сведении о том, является ли она короткой или длинной, насколько интенсивными будут ее запросы к устройствам ввода-вывода, насколько важно ее быстрое выполнение и т. д. Дифференциация обслуживания при квантовании базируется на «истории существования» потока в системе.<o:p></o:p></span></p> <p><span> <o:p></o:p></span></p> <p style="text-align: center;"><span><o:p> </o:p></span></p> <p><span> <o:p></o:p></span></p> <p><span><!--[if gte vml 1]><v:shape id="_x0000_i1027"
 type="#_x0000_t75" style='width:432.75pt;height:316.5pt'>
 <v:imagedata src="Тема%20№3.files/image005.png" o:title=""/>
</v:shape><![endif]--><img src="Тема%20№3.files/image006.jpg" v:shapes="_x0000_i1027"><o:p></o:p></span></p> <p style="text-align: center;"><span>Рисунок <a></a>3 – Квантование с предпочтением потоков, интенсивно обращающихся к вводу-выводу<o:p></o:p></span></p> <p><span><o:p> </o:p></span></p> <p><b><span>3.4 </span></b><b><span>Алгоритмы планирования, основанные на приоритетах.<o:p></o:p></span></b></p> <p><span>Другой важной концепцией, лежащей в основе многих вытесняющих алгорит</span><span>мов планирования, является <i>приоритетное обслуживание. </i>Приоритетное обслуживание предполагает наличие у потоков некоторой изначально известной характеристики – приоритета, на основании которой определяется порядок их выполнения. <i>Приоритет </i>– это число, характеризующее степень привилегированности потока при использовании ресурсов вычислительной машины, в част<span>ности процессорного времени: чем выше приоритет, тем выше привилегии, тем </span>меньше времени будет проводить поток в очередях.<o:p></o:p></span></p> <p><span>Приоритет может выражаться целым или дробным, положительным или отрицательным значением. В некоторых ОС принято, что приоритет потока тем выше, чем больше (в арифметическом смысле) число, обозначающее приоритет. В других системах, наоборот, чем меньше число, тем выше приоритет.<o:p></o:p></span></p> <p><span>В большинстве операционных систем, поддерживающих потоки, приоритет потока непосредственно связан с приоритетом процесса, в рамках которого выполняется данный поток. Приоритет процесса назначается операционной системой <span>при его создании. Значение приоритета включается в описатель процесса и ис</span>пользуется при назначении приоритета потокам этого процесса. При назначении приоритета вновь созданному процессу ОС учитывает, является этот процесс системным или прикладным, каков статус пользователя, запустившего процесс, было ли явное указание пользователя на присвоение процессу определенного уровня приоритета. Поток может быть инициирован не только по команде пользователя, но и в результате выполнения системного вызова другим потоком. В этом случае при назначении приоритета новому потоку ОС должна принимать во внимание значение параметров системного вызова.<o:p></o:p></span></p> <p><span>Во многих ОС предусматривается возможность изменения приоритетов в тече<span>ние жизни потока. Изменение приоритета могут происходить по инициативе </span>самого потока, когда он обращается с соответствующим вызовом к операционной системе, или по инициативе пользователя, когда он выполняет соответствующую команду. Кроме того, ОС сама может изменять приоритеты потоков в зависимости от ситуации, складывающейся в системе. В последнем случае при<span>оритеты называются <i>динамическими </i>в отличие от неизменяемых, <i>фиксирован</i></span><i>ных </i>приоритетов.<o:p></o:p></span></p> <p><span>От того, какие приоритеты назначены потокам, существенно зависит эффективность работы всей вычислительной системы. В современных ОС во избежание разбалансировки системы, которая может возникнуть при неправильном назначении приоритетов, возможности пользователей влиять на приоритеты процессов и потоков стараются ограничивать. При этом обычные пользователи, как правило, не имеют права повышать приоритеты своим потокам, это разрешено делать (да и то в определенных пределах) только администраторам. В большин<span>стве же случаев ОС присваивает приоритеты потокам по умолчанию.</span><o:p></o:p></span></p> <p><span>В качестве примера рассмотрим схему назначения приоритетов потокам, приня</span><span>тую в операционной системе </span><span>Windows NT </span><span>(рисунок 4). В системе определено 32 уровня приоритетов и два класса потоков – потоки реального времени и потоки с переменными приоритетами. Диапазон от 1 до 15 включительно отведен <span>для потоков с переменными приоритетами, а от 16 до 31 </span>–<span> для более критичных ко времени потоков реального времени (приоритет 0 зарезервирован для систем</span>ных целей).<o:p></o:p></span></p> <p><span><o:p> </o:p></span></p> <p style="text-align: center;"><span><o:p> </o:p></span></p> <p><span> </span><span><o:p></o:p></span></p> <p style="text-align: center;"><span><!--[if gte vml 1]><v:shape
 id="_x0000_i1028" type="#_x0000_t75" style='width:464.25pt;height:240pt'>
 <v:imagedata src="Тема%20№3.files/image007.png" o:title=""/>
</v:shape><![endif]--><img src="Тема%20№3.files/image008.jpg" v:shapes="_x0000_i1028"><o:p></o:p></span></p> <p style="text-align: center;"><span><o:p> </o:p></span></p> <p style="text-align: center;"><span>Рисунок <a></a>4 – Схема назначения приоритетов в </span><span>Windows NT</span><span><o:p></o:p></span></p> <p><span> <o:p></o:p></span></p> <p><span>При создании процесса он в зависимости от класса получает но умолчанию базовый приоритет в верхней или нижней части диапазона. Базовый приоритет <span>процесса в дальнейшем может быть повышен или понижен операционной систе</span><span>мой. Первоначально поток получает значение базового приоритета из диапазона базового приоритета процесса, в котором он был создан. Пусть, например, значе</span><span>ние базового приоритета некоторого процесса равно </span><b>К</b><span>. Тогда все потоки данного </span>процесса получат базовые приоритеты из диапазона <b>[К-2, К+2]</b>. Отсюда видно, <span>что, изменяя базовый приоритет процесса, ОС может влиять на базовые приори</span>теты его потоков.<o:p></o:p></span></p> <p><span>В </span><span>Windows NT </span><span>с течением времени приоритет потока, относящегося к классу по<span>токов с переменными приоритетами, может отклоняться от базового приоритета </span>потока, причем эти изменения могут быть не связаны с изменениями базового приоритета процесса. ОС может повышать приоритет потока (который в этом случае называется динамическим) в тех случаях, когда поток не полностью использовал отведенный ему квант, или понижать приоритет, если квант был ис<span>пользован полностью. ОС наращивает приоритет дифференцированно в зави</span>симости от того, какого типа событие не дало потоку полностью использовать квант. В частности, ОС повышает приоритет в большей степени потокам, которые ожидают ввода с клавиатуры (интерактивным приложениям) и в меньшей <span>степени </span>–<span> потокам, выполняющим дисковые операции. Именно на основе дина</span>мических приоритетов осуществляется планирование потоков. Начальной точкой отсчета для динамического приоритета является значение базового приоритета потока. Значение динамического приоритета потока ограничено снизу его <span>базовым приоритетом, верхней же границей является нижняя граница диапазона </span>приоритетов реального времени.<o:p></o:p></span></p> <p><span>Существуют две разновидности приоритетного планирования: обслуживание с относительными приоритетами и обслуживание с абсолютными приоритетами.<o:p></o:p></span></p> <p><span>В обоих случаях выбор потока на выполнение из очереди готовых осуществляется одинаково: выбирается поток, имеющий наивысший приоритет. Однако про<span>блема определения момента смены активного потока решается по-разному. В сис</span><span>темах с относительными приоритетами активный поток выполняется до тех пор, </span>пока он сам не покинет процессор, перейдя в состояние ожидания (или же произойдет ошибка, или поток завершится).<o:p></o:p></span></p> <p><span>В системах с абсолютными приоритетами выполнение активного потока прерывается кроме указанных выше причин, еще при одном условии: если в очереди готовых потоков появился поток, приоритет которого выше приоритета активного потока. В этом случае прерванный поток переходит в состояние готовности (рисунок 5)<i>.</i><o:p></o:p></span></p> <p><span>В системах, в которых планирование осуществляется на основе относительных <span>приоритетов, минимизируются затраты на переключения процессора с одной ра</span>боты на другую. С другой стороны, здесь могут возникать ситуации, когда одна задача занимает процессор долгое время. Ясно, что для систем разделения времени и реального времени такая дисциплина обслуживания не подходит: интерактивное приложение может ждать своей очереди часами, пока вычислительной задаче не потребуется ввод-вывод. А вот в системах пакетной обработки (в том числе известной ОС </span><span>OS</span><span>/360) относительные приоритеты используются широко). <o:p></o:p></span></p> <p style="text-align: center;"><span><o:p> </o:p></span></p> <p><span> </span><span><o:p></o:p></span></p> <p style="text-align: center;"><span><!--[if gte vml 1]><v:shape
 id="_x0000_i1029" type="#_x0000_t75" style='width:421.5pt;height:363pt'>
 <v:imagedata src="Тема%20№3.files/image009.png" o:title=""/>
</v:shape><![endif]--><img src="Тема%20№3.files/image010.jpg" v:shapes="_x0000_i1029"><o:p></o:p></span></p> <p style="text-align: center;"><span>Рисунок 5 – Графы состояний потоков в системах с относительными и абсолютными приоритетами<o:p></o:p></span></p> <p><span> <o:p></o:p></span></p> <p><span>В системах с абсолютными приоритетами время ожидания потока в очередях <span>может быть сведено к минимуму, если ему назначить самый высокий приоритет. </span>Такой поток будет вытеснять из процессора все остальные потоки (кроме пото<span>ков, имеющих такой же наивысший приоритет). Это делает планирование на основе абсолютных приоритетов подходящим для систем управления объектами, в </span>которых важна быстрая реакция на событие.<o:p></o:p></span></p> <p><span><o:p> </o:p></span></p> <p><b><span>3.5 Особенности реализации мультизадачности в системах реального времени<o:p></o:p></span></b></p> <p><span>Еще одна разновидность мультипрограммирования используется в <i>системах ре</i></span><i><span>ального времени, </span></i><span>предназначенных для управления от компьютера различными <span>техническими объектами (например, станком, спутником, научной эксперименталь</span>ной установкой и т. д.) или технологическими процессами (например, гальванической линией, доменным процессом и т. п.). Во всех этих случаях существует пре<span>дельно допустимое время, в течение которого должна быть выполнена та или иная </span>управляющая объектом программа. В противном случае может произойти авария: <span>спутник выйдет из зоны видимости, экспериментальные данные, поступающие с дат</span>чиков, будут потеряны, толщина гальванического покрытия не будет соответство<span>вать норме. Таким образом, критерием эффективности здесь является способность выдерживать заранее заданные интервалы времени между запуском программы и получением результата (управляющего воздействия). Это время называется време</span><span>нем реакции системы, а соответствующее свойство системы </span>–<span> реактивностью. Требо</span><span>вания ко времени реакции зависят от специфики управляемого процесса. Кон</span><span>троллер робота может требовать от встроенного компьютера ответ в течение </span><span>менее 1 мс, в то время как при моделировании полета может быть приемлем от</span>вет в 40 мс.<o:p></o:p></span></p> <p><span>В системах реального времени мультипрограммная смесь представляет собой фик<span>сированный набор заранее разработанных программ, а выбор программы на выпол</span><span>нение осуществляется по прерываниям (исходя из текущего состояния объекта) </span>или в соответствии с расписанием плановых работ.<o:p></o:p></span></p> <p><span>Способность аппаратуры компьютера и ОС к быстрому ответу зависит в основном от скорости переключения с одной задачи на другую и, в частности, от скорости <span>обработки сигналов прерывания. Если при возникновении прерывания про</span><span>цессор должен опросить сотни потенциальных источников прерывания, то реак</span><span>ция системы будет слишком медленной. Время обработки прерывания в систе</span>мах реального времени часто определяет требования к классу процессора даже при небольшой его загрузке.<o:p></o:p></span></p> <p><span>В системах реального времени не стремятся максимально загружать все устройства, наоборот, при проектировании программного управляющего комплекса обычно закладывается некоторый «запас» вычислительной мощности на случай пиковой нагрузки. Статистические аргументы о низкой вероятности возникновения пиковой нагрузки, основанные на том, что вероятность одновременного возникновения большого количества независимых событий очень мала, не применимы ко многим ситуациям в системах управления. Например, в системе управления атомной электростанцией в случае возникновения крупной аварии атомного реактора многие аварийные датчики сработают одновременно и создадут коррелированную нагрузку. Если система реального времени не спроектирована для поддержки пиковой нагрузки, то может случиться так, что система не справится с работой именно тогда, когда она нужна в наибольшей степени.<o:p></o:p></span></p> <p><span><o:p> </o:p></span></p> <p><b><span>3.6 </span></b><b><span>Назначение, механизм и типы прерываний<o:p></o:p></span></b></p> <p><b><span>Назначение и типы прерываний.</span></b><span><o:p></o:p></span></p> <p><span>Система прерываний переводит процессор на выполнение потока команд, отличного от того, который выполнялся до сих пор, с последующим возвратом к исходному коду. Механизм прерываний очень похож на механизм выполнения процедур. Это на самом деле так, хотя между этими механизмами имеется важное отличие. Переключение по прерыванию отличается от переключения, которое происходит по команде безусловного или условного перехода, предусмотренной программистом в потоке команд приложения. Переход по команде происходит в заранее определенных программистам точках программы и в зависимости от исходных данных, обрабатываемых программой. Прерывание же происходит в произвольной точке потока команд программы, которую программист не может прогнозировать. Прерывание возникает либо в зависимости от внешних, по отношению к процессу выполнения программы событий, либо при появлении <i>непредвиденных</i> аварийных ситуаций в процессе выполнения данной программы. Сходство же прерываний с процедурами состоит в том, что в обоих случаях выполняется некоторая подпрограмма, обрабатывающая специальную ситуацию, а затем продолжается выполнение основной ветви программы.<o:p></o:p></span></p> <p><span>В зависимости от источника прерывания делятся на три больших класса: внешние; внутренние: программные.<o:p></o:p></span></p> <p><i><span>Внешние </span></i><span>прерывания могут возникать в результате действий пользователя или оператора за терминалом, или же в результате поступления сигналов от аппаратных устройств – сигналов завершения операций ввода-вывода, вырабатываемых контроллерами внешних устройств компьютера, такими как принтер или нако­питель на жестких дисках, или же сигналов от датчиков управляемых компьютером технических объектов. Внешние прерывания называют также <i>аппаратными</i>, отражая тот факт, что прерывание возникает вследствие подачи некоторой аппаратурой (например, контроллером принтера) электрического сигнала, который передается (возможно, проходя через другие блоки компьютера, например кон­троллер прерывании) на специальный вход прерывания процессора. Данный класс прерывании является <i>асинхронным </i>по отношению к потоку инструкций преры­ваемой программы. Аппаратура процессора работает так, что асинхронные пре­рывания возникают между выполнением двух соседних инструкций, при этом системе после обработки прерывания продолжает выполнение процесса, уже начиная со следующей инструкции.<o:p></o:p></span></p> <p><i><span>Внутренние </span></i><span>прерывания, называемые также <i>исключениями (ехерtion), </i>происхо­дят <i>синхронно </i>выполнению программы при появлении аварийной ситуации и ходе исполнения некоторой инструкции программы. Примерами исключений явля­ются деление на нуль, ошибки защиты памяти, обращения по несуществующему адресу, попытка выполнить привилегированную инструкцию в пользовательском режиме и т. п. Исключения возникают непосредственно в ходе выполнения так­тов команды («внутри»» выполнения).<o:p></o:p></span></p> <p><i><span>Программные </span></i><span>прерывания отличаются от предыдущих двух классов тем, что они по своей сути не являются «истинными» прерываниями. Программное прерыва­ние возникает при выполнении особой команды процессора, выполнение которой имитирует прерывание, то есть переход на новую последовательность инструк­ций. Причины использования программных прерываний вместо обычных инст­рукций вызова процедур будут изложены ниже, после рассмотрения механизма прерываний.<o:p></o:p></span></p> <p><span>Прерываниям<b> </b>приписывается приоритет, с помощью которого они ранжируются по степени важности и срочности. О прерываниях, имеющих одинаковое значе­ние приоритета, говорят, что они относятся к одному <i>уровню приоритета </i>преры­ваний.<o:p></o:p></span></p> <p><span>Прерывания обычно обрабатываются модулями операционной системы, так как действия, выполняемые по прерыванию, относятся к управлению разделяемыми ресурсами вычислительной системы - принтером, диском, таймером, процессо­ром и т. п. Процедуры, вызываемые по прерываниям, обычно называют <i>обработ­чиками прерываний, </i>или <i>процедурами обслуживания прерываний (1nterruptServiceRoutine, ISR). </i>Аппаратные прерывания обрабатываются драйверами соответствую­щих внешних устройств, исключения – специальными модулями ядра, а про­граммные прерывания - процедурами ОС, обслуживающими системные вызовы. Кроме этих модулей в операционной системе может находиться так называемый диспетчер прерываний, который координирует работу отдельных обработчиков прерывании.<o:p></o:p></span></p> <p><span> <o:p></o:p></span></p> <p><b><span>Механизм прерываний.</span></b><span><o:p></o:p></span></p> <p><span>Механизм прерывании поддерживается аппаратными средствами компьютера и программными средствами операционной системы. Аппаратная поддержка преры­ваний имеет спои особенности, зависящие от типа процессора и других аппарат­ных компонентов, передающих сигнал запроса прерывания от внешнего устрой­ства к процессору (таких, как контроллер внешнего устройства, шины подклю­чения внешних устройств, контроллер прерываний, являющийся посредником между сигналами шины и сигналами процессора). Особенности аппаратной реализации прерываний оказывают влияние на средства программной поддержки прерываний, работающие в составе ОС.<o:p></o:p></span></p> <p><span>Существуют два основных способа, с помощью которых шины выполняют прерывания: <i>векторный </i>(<i>vectored</i>) и <i>опрашиваемый (polled). </i>В обоих способах про­цессору предоставляется информация об уровне приоритета прерывания на шине подключения внешних устройств. В случае векторных прерывании в процессор передается также информация о начальном адресе программы обработки возник­шего прерывания - <i>обработчика прерываний.</i><o:p></o:p></span></p> <p><span>Устройствам, которые используют векторные прерывания, назначается <i>вектор прерываний. </i>Он представляет собой электрический сигнал, выставляемый на соответствующие шины процессора и несущий в себе информацию об определен­ном, закрепленном за данным устройством номере, который идентифицирует соответствующий обработчик прерываний. Этот вектор может быть фиксированным, конфигурируемым<b> </b>(например, с использованием переключателей) или программируемым. Операционная система может предусматривать процедуру регистра­ции вектора обработки прерывании для определенного устройства, которая свя­зывает некоторую подпрограмму обработки прерываний с определенным вектором. При получении сигнала запроса прерывания процессор выполняет специальный цикл подтверждения прерывания, в котором устройство должно идентифицировать себя. В течение этот цикла устройство отвечает, выставляя на шину вектор прерываний. Затем процессор использует этот вектор для нахождения обработ­чика данного прерывания. Примером шины подключения внешних устройств, которая поддерживает векторные прерывания, является шина VMEbus.<o:p></o:p></span></p> <p><span>При использовании опрашиваемых прерываний процессор получает от запросившего прерывание устройства только информацию об уровне приоритета прерывания (например, номере QRI на шине ISA или номере IPL на шине SBus компьютеров SPARC). С каждым уровнем прерываний может быть связано несколько устройств и соответственно несколько программ – обработчиков прерываний. При возникновении прерывания процессор должен определить, какое устройст­во из тех, которые связаны с данным уровнем прерываний, действительно запросило прерывание. Это достигается вызовом всех обработчиков прерываний для данного уровня приоритета, пока один из обработчиков не подтвердит, что пре­рывание пришло от обслуживаемого им устройства. Если же с каждым уровнем прерываний связано только одно устройство, то определение нужной программы обработки прерывания происходит немедленно, как и при векторном прерывании. Опрашиваемые прерывания поддерживают шины ISA, EISA, MCA, PCI и Sbus.<o:p></o:p></span></p> <p><span>Механизм прерываний некоторой аппаратной платформы может сочетать век­торный и опрашиваемый типы прерываний. Типичным примером такой реализа­ции является платформа персональных компьютеров на основе процессоров Intel Pentium. Шины PCI,ISA, EISA или MCA, используемые в этой платформе в ка­честве шин подключения внешних устройств, поддерживают механизм опрашиваемых прерываний. Контроллеры периферийных устройств выставляют на шину не вектор, а сигнал запроса прерывания определенного уровня IRQ. Одна­ко в процессоре Pentium система прерываний является векторной. Вектор прерываний в процессор Pentium поставляет контроллер прерываний, который ото­бражает поступающий от шины сигнал IRQ на определенный номер вектора.<o:p></o:p></span></p> <p><span>Вектор прерываний, передаваемый в процессор, представляет собой целое число в диапазоне от 0 до 255, указывающее на одну из 256 программ обработки пре­рываний, адреса которых хранятся в таблице обработчиков прерываний. В том случае, когда к каждой линии IRQ, подключается только одно устройство, проце­дура обработки прерываний работает так, как если бы система прерываний была чисто векторной, то есть процедура не выполняет никаких дополнительных опросов для выяснения того, какое именно устройство запросило прерывание. Однако при совместном использовании одного уровня IRQ несколькими уст­ройствами программа обработки прерываний должка работать в соответствии со схемой опрашиваемых прерываний, то есть дополнительно выполнить опрос всех устройств, подключенных к данному уровню IRQ.<o:p></o:p></span></p> <p><span>Механизм прерываний чаще всего поддерживает <i>прииритезацию </i>и <i>маскирование </i>прерываний. Приоритезация означает, что все источники прерываний делятся на классы и каждому классу назначается свой уровень приоритета запроса на преры­вание. Приоритеты могут обслуживаться как <i>относительные </i>и <i>абсолютные. </i>Об­служивание запросов прерываний по схеме с относительными приоритетами за­ключается в том, что при одновременном поступлении запросов прерываний из разных классов выбирается запрос, имеющий высший приоритет. Однако в дальнейшем при обслуживании<b> </b>этого запроса процедура обработки прерывания уже не откладывается даже в том случае, когда появляются более приоритетные запросы – решение о выборе нового запроса принимается только в момент за­вершения обслуживания очередного прерывания. Если же более приоритетным прерываниям разрешается приостанавливать работу процедур обслуживания ме­нее приоритетных прерываний, то это означает, что работает схема приоритезации с абсолютными приоритетами.<o:p></o:p></span></p> <p><span>Если процессор (или компьютер, когда поддержка приоритезации прерываний вынесена во внешний по отношению к процессору блок) работает по схеме с абсолютными приоритетами, то он поддерживает в одном из своих внутренних ре­гистров переменную, фиксирующую уровень приоритета обслуживаемого в дан­ный момент прерывания. При поступлении запроса из определенного класса его приоритет сравнивается с текущим приоритетом процессора, и если приоритет запроса выше, то текущая процедура обработки прерываний вытесняется, а по завершении обслуживания нового прерывания происходит возврат к прерван­ной процедуре.<o:p></o:p></span></p> <p><span>Упорядоченное обслуживание запросов прерываний наряду со схемами приоритетной обработки запросов может выполняться механизмом маскирования запросов. Собственно говоря, в описанной схеме абсолютных приоритетов выполняет­ся маскирование – при обслуживании некоторого запроса все запросы с равным или более низким приоритетом маскируются, то есть не обслуживаются. Схема маскирования предполагает возможность временного маскирования прерываний любого класса независимо от уровня приоритета.<o:p></o:p></span></p> <p><span>Обобщенно последовательность действий аппаратных и программных средств по обработке прерывания можно описать следующим образом:<o:p></o:p></span></p> <p><span>1) При возникновении сигнала (для аппаратных прерываний) или условия (для внутренних прерываний) прерывания происходит первичное аппаратное распознавание типа прерывания, Если прерывания данного типа в настоящий момент запрещены (приоритетной схемой или механизмом маскирования), то процессор продолжает поддерживать естественный ход выполнения команд. В противном случае в зависимости от поступившей в процессор информации (уровень прерывания, вектор прерывания или тип условия внутреннего прерывания) происходит автоматический вызов процедуры обработки прерывания, адрес которой находится в специальной таблице операционной системы размещаемой либо в регистрах процессора, либо в определенном месте оперативной памяти.<o:p></o:p></span></p> <p><span>2) Автоматически сохраняется некоторая часть контекста прерванного потока, которая позволит ядру возобновить исполнение потока процесса после обработки прерывания. В это подмножество обычно включаются значения счетчика команд, слова состояния машины, хранящего признаки основных режимов работы процессора (пример такого слова – регистр EFLAGS в Intel Pentium), а также нескольких регистров общего назначения, которые требуются программе обработки прерывания. Может быть сохранен и полный контекст процесса, если ОС обслуживает данное прерывание со сменой процесса. Однако в общем случае это не обязательно, часто обработка прерываний выполняется без вытеснения текущего процесса.<o:p></o:p></span></p> <p><span>3) Одновременно с загрузкой адреса процедуры обработки прерываний в счетчик команд может автоматически выполняться загрузка нового значения слов состояния машины (или другой системной структуры, например селектор кодового сегмента в процессоре Pentium), которое определяет режимы работы процессора при обработке прерывания, в том числе работу в привилегированном режиме. В некоторых моделях процессором переход в привилегированный режим за счет смены состояния машины при обработке прерывания является единственным способом смены режима. Прерывания практически во всех мультипрограммных ОС обрабатываются в привилегированном режиме модулями ядра, так как при этом обычно нужно выполнить ряд критических операций, с которых зависит жизнеспособность системы, – управлять внешними устройствами, перепланировать потоки и т. п.<o:p></o:p></span></p> <p><span>4) Временно запрещаются прерывания данного типа, чтобы не образовалась очередь вложенных друг в друга потоков одной и той же процедуры. Детали выполнения этой операции зависят от особенностей аппаратной платформы, например, может использоваться механизм маскирования прерывании. Многие процессоры автоматически устанавливают признак запрета прерываний в начале цикла обработки прерывания, в противном случае это делает программа обработки прерываний.<o:p></o:p></span></p> <p><span>5) После того как прерывание обработано ядром операционной системы, пре­рванный контекст восстанавливается и работа потока возобновляется с пре­рванного места. Часть контекста восстанавливается аппаратно по команде возврата из прерываний (например, адрес следующей команды и слово со­стояния машины), а часть – программным способом, с помощью явных ко­манд извлечения данных из стека. При возврате из прерывания блокировка повторных прерываний данного типа снимается.<o:p></o:p></span></p> <p><span> <o:p></o:p></span></p> <p><b><span>Программные прерывания.</span></b><span><o:p></o:p></span></p> <p><span>Программное порывание реализует один из способов перехода на подпрограмму с помощью специальной инструкции процессора, такой как INT в процессо­рах Intel Pentium, trap в процессорах Motorola, syscall в процессорах MIPS или Ticc в процессорах SPARC. При выполнении команды программного прерывания процессор отрабатывает ту же последовательность действии, что и при возник­новении внешнего или внутреннего прерывания, но только происходит это в предсказуемой точке программы – там, где программист поместил данную ко­манду.<o:p></o:p></span></p> <p><span>Практически все современные процессоры имеют в системе команд инструкции программных прерываний. Одной из причин появления инструкций программ­ных прерываний в системе команд процессоров является то, что их использова­ние часто приводит к более компактному коду программ по сравнению с исполь­зованием стандартных команд выполнения процедур. Это объясняется тем, что разработчики процессора обычно резервируют для обработки прерываний не­большое число возможных подпрограмм, так что длина операнда в команде программного прерывания, который указывает на нужную подпрограмму, меньше, чем в команде перехода на подпрограмму. Например, в процессоре х86 предусмотрена возможность применения 256 программ обработки прерываний, поэто­му в инструкции INT операнд имеет длину в один байт (а инструкция INT 3, кото­рая предназначена для вызова отладчика, вся имеет длину один байт). Значение операнда команды INT просто является индексом в таблице из 256 адресов под­программ обработки прерываний, один из которых и используется для перехода по команде INT. При использовании команды CALL потребовался бы уже не одно­байтовый, а двух- или четырехбайтовый операнд. Другой причиной применения программных прерываний вместо обычных инструкций вызова подпрограмм является возможность смены пользовательского режима на привилегированный, одновременно с вызовом процедуры – это свойство программных прерываний поддерживается большинством процессоров.<o:p></o:p></span></p> <p><span>В результате программные прерывания часто используются для выполнения ограниченного количества вызова функций ядра операционной системы, то есть системных вызовов.<o:p></o:p></span></p> <p><span><o:p> </o:p></span></p> <p><b><span>3.6 </span></b><b><span>Системные вызовы и схемы их обработки<o:p></o:p></span></b></p> <p><span>Системный вызов</span><span><span> </span></span><span>– приложение обращается к операционной системе для выполнения действия, оформленного как процедура (или набор процедур) кодового сегмента ОС. С помощью системного вызова можно упростить прикладную программу или выполнить действия, запрещенные в пользовательском режиме, например обмен данными с устройством ввода-вывода.<o:p></o:p></span></p> <p><span>Реализация системных вызовов должна удовлетворять следующим требованиям:<o:p></o:p></span></p> <p><![if !supportLists]><span><span>–<span> </span></span></span><![endif]><span>обеспечивать переключение в привилегированный режим;<o:p></o:p></span></p> <p><![if !supportLists]><span><span>–<span> </span></span></span><![endif]><span>обладать высокой скоростью вызова процедур ОС;<o:p></o:p></span></p> <p><![if !supportLists]><span><span>–<span> </span></span></span><![endif]><span>обеспечивать по возможности единообразное обращение к системным вызовам для всех аппаратных платформ, на которых работает ОС;<o:p></o:p></span></p> <p><![if !supportLists]><span><span>–<span> </span></span></span><![endif]><span>допускать легкое расширение набора системных вызовов;<o:p></o:p></span></p> <p><![if !supportLists]><span><span>–<span> </span></span></span><![endif]><span>обеспечивать контроль со стороны ОС за корректным использованием системных вызовов.<o:p></o:p></span></p> <p><span>Первое требование для большинства аппаратных платформ может быть выполнено только с помощью механизма программных прерываний. Некоторые из этих требований взаимно противоречивы.<o:p></o:p></span></p> <p><span>Для обеспечения высокой скорости было бы полезно использовать векторные свойства системы программных прерываний, имеющиеся во многих процессорах, то есть закрепить за каждым системным вызовом определенное значение вектора.<o:p></o:p></span></p> <p><span><span> </span>Приложение при таком способе вызова непосредственно указывает в аргументе запроса значение вектора, после чего управление немедленно передается требуемой процедуре операционной системы (рисунок 5.1, а). Однако этот децентрализованный способ передачи управления привязан к особенностям аппаратной платформы, а также не позволяет операционной системе легко модифицировать набор системных вызовов и контролировать их использование. Например, в процессоре Pentium количество системных вызовов определяется количеством векторов прерываний, выделенных для этой цели из общего пула в 256 элементов (часть которых используется под аппаратные прерывания и обработку исключений). Добавление нового системного вызова требует от системного программиста поиска свободного элемента в таблице прерываний, которого к тому же на каком-то этапе развития ОС может и не оказаться.<o:p></o:p></span></p> <p><span>В большинстве ОС системные вызовы обслуживаются по централизованной схеме, основанной на существовании диспетчера системных вызовов (рисунок 5.1, б). При любом системном вызове приложение выполняет программное прерывание с определенным и единственным номером вектора. Например, ОС Linux использует для системных вызовов команду INT 80h, а ОС Windows NT (при работе на платформе Pentium) — INT 2Eh. Перед выполнением программного прерывания приложение передает операционной системе номер системного вызова, который является индексом в таблице адресов процедур ОС, реализующих системные вызовы (таблица</span><span><span> </span></span><span>sysent</span><span><span> </span></span><span>на рисунке 5.1). Способ передачи номера системного вызова зависит от реализации, например номер можно поместить в определенный регистр общего назначения процессора или передать через стек. Также некоторым способом передаются аргументы системного вызова, они могут, как помещаться в регистры общего назначения, так и передаваться через стек или массив, находящийся в оперативной памяти.<o:p></o:p></span></p> <p><span>Диспетчер системных вызовов представляет собой простую программу, которая сохраняет содержимое регистров процессора в системном стеке (поскольку в результате программного прерывания процессор переходит в привилегированный режим), проверяет, попадает ли запрошенный номер вызова в поддерживаемый ОС диапазон и передает управление процедуре ОС, адрес которой задан в таблице адресов системных вызовов.<o:p></o:p></span></p> <p style="text-align: center;"><span><!--[if gte vml 1]><v:shape
 id="_x0000_i1030" type="#_x0000_t75" style='width:402pt;height:287.25pt'>
 <v:imagedata src="Тема%20№3.files/image011.png" o:title=""/>
</v:shape><![endif]--><img src="Тема%20№3.files/image012.jpg" v:shapes="_x0000_i1030"><o:p></o:p></span></p> <p style="text-align: center;"><span><!--[if gte vml 1]><v:shape id="_x0000_i1031"
 type="#_x0000_t75" style='width:462.75pt;height:301.5pt'>
 <v:imagedata src="Тема%20№3.files/image013.png" o:title=""/>
</v:shape><![endif]--><img src="Тема%20№3.files/image014.jpg" v:shapes="_x0000_i1031"><o:p></o:p></span></p> <p style="text-align: center;"><span>Рисунок 5.1 – Децентрализованная и централизованная схемы обработки системных вызовов<o:p></o:p></span></p> <p><span> <o:p></o:p></span></p> <p><span>Процедура реализации системного вызова извлекает из системного стека аргументы и выполняет заданное действие.<o:p></o:p></span></p> <p><span>После завершения работы системного вызова управление возвращается диспетчеру, при этом он получает также код завершения этого вызова. Диспетчер восстанавливает регистры процессора, помещает в определенный регистр код возврата и выполняет инструкцию возврата из прерывания, которая восстанавливает непривилегированный режим работы процессора.<o:p></o:p></span></p> <p><span>Для всех системных вызовов в библиотеках, предоставляемых компилятором С, имеются так называемые «заглушки» - «stub». Каждая заглушка оформлена как С-функция и содержит несколько ассемблерных строк, выполняющих инструкции программного прерывания. Пользовательская программа вызывает заглушку, которая вызывает процедуру ОС.<o:p></o:p></span></p> <p><span>Операционная система может выполнять системные вызовы в</span><span><span> </span></span><span>синхронном</span><span><span> </span></span><span>или</span><span><span> </span></span><span>асинхронном</span><span><span> </span></span><span>режимах.</span><span><span> </span></span><span>Синхронный системный вызов</span><span><span> </span></span><span>– процесс приостанавливается (переводится планировщиком ОС в состояние ожидания) до тех пор, пока системный вызов не выполнит всю требующуюся от него работу (рисунок 5.2, а). После этого планировщик переводит процесс в состояние готовности и при очередном выполнении процесс гарантированно может воспользоваться результатами завершившегося к этому времени системного вызова.</span><span><span> </span></span><span>Синхронные вызовы</span><span><span> </span></span><span>- блокирующие, вызвавший системное действие процесс блокируется до его завершения.<o:p></o:p></span></p> <p><span>Асинхронный системный вызов</span><span><span> </span></span><span>не переводит процесс в режим ожидания и после выполнения некоторых начальных системных действий управление возвращается прикладному процессу (рисунок 5.2, б).<o:p></o:p></span></p> <p style="text-align: center;"><span><!--[if gte vml 1]><v:shape id="Рисунок_x0020_19" o:spid="_x0000_i1032"
 type="#_x0000_t75" alt="http://ok-t.ru/studopediaru/baza3/314430007015.files/image004.jpg"
 style='width:218.25pt;height:284.25pt;visibility:visible'>
 <v:imagedata src="Тема%20№3.files/image015.jpg" o:title=""/>
</v:shape><![endif]--><img src="Тема%20№3.files/image015.jpg" alt="http://ok-t.ru/studopediaru/baza3/314430007015.files/image004.jpg" v:shapes="Рисунок_x0020_19"></span><span><o:p></o:p></span></p> <p style="text-align: center;"><span>Рисунок 5.2 - Синхронные и асинхронные системные вызовы<o:p></o:p></span></p> <p><span> <o:p></o:p></span></p> <p><span>Большинство системных вызовов в операционных системах являются синхронными, что избавляет приложение от работы по выяснению момента появления результата вызова. Вместе с тем в новых версиях операционных систем количество асинхронных системных вызовов постепенно увеличивается, что позволяет разрабатывать сложные приложения. Асинхронные системные вызовы нужны в операционных системах на основе микроядерного подхода, где в пользовательском режиме работает часть ОС.<o:p></o:p></span></p> <p><span><o:p> </o:p></span></p> <p><span>Список литературы:<o:p></o:p></span></p> <p><![if !supportLists]><span><span>1.<span> </span></span></span><![endif]><span>Олифер, В.Г. Сетевые операционные системы / В.Г. Олифер, Н.А. Олифер. – СПб.: Питер, 2002.<o:p></o:p></span></p> <p><span><o:p> </o:p></span></p> </div> 
 <A HREF="../theory.htm">Оглавление</A>                
<p>&nbsp;</p>
        </table>
<table width="100%" height=25px border="0" cellpadding="0" cellspacing="3" bordercolor="#316AC5" background="../Оболочка/images/background.jpg">
  <tr >
  <td align=center><var><B><b>(С)  БГУИР</b></var></td>
  </tr>
</table>
</BODY></HTML>